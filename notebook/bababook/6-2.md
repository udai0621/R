## 2-1.説明の進め方

-   HMC法：ハミルトニアンモンテカルロ法
-   HMC法は本来はパラメタの推定とはなんの関係もなく、乱数生成のためのアルゴリズム
-   ただし、パラメタ推定と乱数生成の繋がりを理解しないと、Stanを理解することは困難。
-   Stanを使うということを前提として、分析の結果の解釈ができることを目標。

## 2-2.ベイズの定理と事前確率・事後確率の関係

-   ベイズ定理：データ(観測値)を用いて、事前確率を事後確率に更新するための計算式。

    -   事前確率：データを手にいれる前に想定していた確率のこと。
    -   事後確率：データを用いて事前確率を修正した結果の確率のこと。

-   例：明日の気温の予測

    -   よくわからないけど、「20度以上になる確率」は40％程度かな。→事前確率
    -   昨日の気温が25度だあったというデータが得られた。
    -   今日も暖かくなるかもしれないから、「20度以上になる確率」を70%に更新→事後確率
    -   今日の速報値が26度であったので、「20度以上になる確率」を90％に更新→事後確率

-   データが手に入るたびに事後確率を更新させることが可能。

## 2-3.ベイズ更新(例題)

-   男性が10人、女性が10人のクラスがあった。

-   部屋にはクラスのメンバー1人だけが入室する。

-   この時、その人は女性or男性？

-   特に情報がない状態なので、事前確率は50%

------------------------------------------------------------------------

-   部屋の前に赤いカバンがおいてあった。
-   男性のうち1人、女性のうち3人が赤いカバンを持っている。
-   クラス全体で見ると、4/20人、20％が所持している。
-   女性だけで見ると、3/10人、30％が所持している。
-   従って、女性はクラス平均の1.5倍、赤いカバンをもちやすいということになる。
-   よって、部屋の中には、1.5倍、女性の可能性が高い。
-   50% × 1.5 =
    75%というのが部屋の中にいる人が女性である確率となる。→事後確率

## 2-4.ベイズの定理

-   *事**後**確**率* = *事**前**確**率* × *修**正**項*
-   修正項の部分を展開する。
-   $事後確率 = 事前確率 \times \frac{女性という条件で、赤いカバンを持つ確率}{平均的に、赤いカバンを持つ確率}$

------------------------------------------------------------------------

-   パラメタを *θ*
    とすると、「部屋の中にいる人（男性か女性か）」がパラメタ。
-   観測値を *y*
    とすると「部屋の前に赤いカバンが置かれていた」というのが観測値。

$$
P(\theta\|y)=P(\theta)\frac{P(y\|\theta)}{P(y)}=\frac{P(y\|\theta)P(\theta)}{P(y)}
$$

## 2-5.事前分布と事後分布

-   要素を確率を対応させてものを確率分布と呼ぶ
-   事前確率の確率分布は{P(男性),P(女性)}={0.5,0.5}→事前分布
-   {P(男性\|赤カバン発見),P(女性\|赤カバン発見)}={0.25,0.75}→事後分布（条件付確率分布）

## 2-6. 補足：確率の基本公式

-   周辺確率： *P*(*θ*=*女**性*) = 10/20 = 0.5 や
    *P*(*y*=*赤**カ**バ**ン**所**持*) = 4/20 = 0.2のこと。
-   同時確率：
    *P*(*θ*=*女**性*,*y*=*赤**カ**バ**ン**所**持*) = 3/20 = 0.15
    のこと。
-   条件付確率：
    *P*(*y*=*赤**カ**バ**ン**所**持*\|*θ*=*女**性*) = 3/10 = 0.3
    のこと。
-   *P*(*θ*=*女**性*,*y*=*赤**カ**バ**ン**所**持*) = *P*(*y*=*赤**カ**バ**ン**所**持*\|*θ*=*女**性*)*P*(*θ*=*女**性*)
    が成り立つ。
-   $P(y=赤カバン所持)=\sum\_{i=1}^2{P(\theta=\theta_i,y=赤カバン所持)}$
    が成り立つ。(*θ*<sub>1</sub> は男性、*θ*<sub>2</sub> は女性)
-   以上から、周辺確率は条件付確率を用いても計算可能。→周辺化

$$
P(y=赤カバン所持)=\sum\_{i=1}^2{P(y=赤カバン所持\|\theta=\theta_i)P(\theta=\theta_i)}
$$

-   上記式を用いると、ベイズの定理は以下のように変形できる。

$$
P(\theta\|y) = P(\theta)\frac{P(y\|\theta)}{\sum\_{i=1}^nP(y\|\theta=\theta_i)P(\theta=\theta_i)}
$$

## 2-7.確率密度と確率と積分(例題)

-   午前5時に起床、さて、今日の気温は何度か？
-   20度と予測したとすると、気温というパラメタ *θ* は20。
-   次にパラメタ *θ*
    の確率を求めるが、問題がある。それは、20度ピッタリという気温になる確率は
    厳密に言えば0％であるということ。小数点を考えれば、ピッタリというのはあり得ない。
-   ということで、区間を設定し、その区間にパラメタ *θ*
    が入る確率を考える。
-   温度計が20.1度を指していたとすると、観測値が得られたことになる。ここから確率分布を事後分布へ更新。
-   この時、「観測値が手に入った後、気温が20\~21度の範囲に収まる確率」はいくらかを捉えるには積分計算を行うこと。

$$
\int\_{20}^{21}p(\theta\|y)d\theta=\int\_{20}^{21}p(\theta)\frac{p(y\|\theta)}{p(y)}d\theta
$$

-   観測値 *y* については入手済み（固定である）ということが大事。

## 2-8.点推定値としてのEAP推定量

-   点推定値が欲しい場合は、事後期待値(EAP)を求める。
-   パラメタの期待値を求めたもの。
-   期待値は「確率×その時の値」の合計から求められる。

$$
\hat\theta\_{eap} = \int\_{-\infty}^{\infty}p(\theta\|y)\theta \~ d\theta = \int\_{-\infty}^{\infty}p(\theta)   \frac{p(y\|\theta)}{p(y)}\theta \~ d\theta
$$

## 2-9.統計モデルと階層的な確率分布

-   統計モデルのパラメタを対象とする。
-   今回は切片だけしかない線形回帰モデルを対象とする。

*y*<sub>*t*</sub> = *θ* + *v*<sub>*t*</sub>,     *v*<sub>*t*</sub> ∼ *N*(0,4)

-   観測誤差の分散についてはすでに把握済みとし、推定するパラメタは切片
    *θ*
-   この時、観測値 *y*<sub>*t*</sub> は以下の確率分布に従って発生する。

*y*<sub>*t*</sub> ∼ *N*(*θ*,4)

-   昨日までの全てのデータ *Y*<sub>*t* − 1</sub>
    を使って、パラメタの事後分布を求める。

*θ* ∼ *p*(*θ*\|*Y*<sub>*t* − 1</sub>)

-   モデルのパラメタ *θ* は事後分布に従う。そのパラメタ *θ*
    を使って、今日の観測値の確率分布 *N*(*θ*,4)
    を予測する。これがベイズ流のモデル推定。

-   確率分布が2つ出てくることに注意。ベイズ推論では、推定すべきパラメタを確率分布として扱う。

## 2-10.無情報事前分布

-   ベイズ推論がクリアしていかなくてはならない課題とその解決策
-   まずは、事前分布をどのようなものにするかという問題。
-   更新前の事前分布についてはテキトーに決めるという状況。ただ。事前分布は事後分布に影響を与える。
-   そこで登場するのが、「無情報事前分布」。例：平均0で分散が
    10000000<sup>2</sup> の正規分布」として幅を持たせること。
-   この場合、パラメタが1になる確率密度も100になる確率密度もともに小さな値になる。
-   つまり、ありうるパラメタの値に等しく平等に低い確率密度を割り当てるということ。
-   これに観測値による更新を行うことで、「確からしいパラメタの値」に高い確率密度、
    「間違いだろうというパラメタの値」に低いパラメタ密度を割り当て直すことができる。

## 2-11.事後分布の計算例

-   割愛。

## 2-12.積分が困難という問題

-   事後分布の確率密度関数は大変複雑な式になる。
-   コンピュータといえど、積分計算不可能なほど。

## 2-13.パラメタ推定と乱数生成アルゴリズムの関係

-   積分が不可能という問題への解決策が、乱数生成アルゴリズム。

-   パラメタ *θ*
    の事後分布の確率密度関数に従う乱数を10000個発生させたとする。

-   パラメタ *θ* のEAP推定量は、10000個の乱数の平均値。

-   「パラメタ *θ* が20\~21の範囲に収まる確率」を計算するなら、パラメタ
    *θ* が20\~21に収まっている
    個数を数えるだけ。5000個あったなら、5000/10000=0.5なので、50%となる。

-   以上が解決策であり、Stanでも採用されているHMC法。

## 2-14.乱数生成で取り組む問題

-   乱数を生成する手法。

#### すでにわかっていること。

-   データは手に入っている。
-   事後分布 *p*(*θ*\|*y*) の確率密度関数も計算可能。
-   パラメタ *θ* を指定すれば、即座に計算可能。

#### わからないこと

-   事後分布 *p*(*θ*\|*y*) の形状は不明。
-   事後分布の積分計算も無理。

## 2-15.乱数生成：メトロポリス法

-   メトロポリス法：汎用的な乱数生成アルゴリズム。基本的な考え方はHMC法と同じ

-   乱数生成する際は、確率密度の高さに対応する形で乱数を採用したい。
    確率密度が低くても、少しくらいなら、採用されて欲しい。

-   メトロポリス法の手順は以下の通り。

    1.  パラメタの初期値をテキトーに定める。

    2.  その初期値における確率密度を計算する。これをp(初期値)とする。

    3.  平均0、分散 *σ*<sup>2</sup> に従う正規乱数を生成する。

    4.  以下の確率密度を計算する。p(初期値＋正規乱数)

    5.  p(初期値＋正規乱数)とp(初期値)を比較する。

        5.1 p(初期値＋正規乱数) \>
        p(初期値)なら、「初期値＋正規乱数」の値を、 乱数として採用する。

        5.2 p(初期値＋正規乱数) \< p(初期値)なら、 p(初期値＋正規乱数) /
        p(初期値)を計算する。 この比率を「提案パラメタ採用確率」と呼ぶ。

             5.2.1 提案パラメタ採用確率で「初期値＋正規乱数」が乱数
                   として採用される。

             5.2.2 「初期値＋正規乱数」が乱数として採用されなければ、
                   初期値をそのまま乱数として採用する。

    6.  乱数として採用されたパラメタを初期値として、1に戻る。

-   メトロポリス法では、確率密度の大小や比率のみに着目。

-   ベイズの定理の右辺の分母*P*(*y*)は定数のため、比率に影響を与えない。
    そのため、分母は無視して計算を進めることができる。

## 2-16.メトロポリス法の問題点

-   メトロポリス法の課題は手順3「平均0、分散*σ*<sup>2</sup>に従う正規乱数を生成する」部分にある。
-   具体的には、分散*σ*<sup>2</sup>をいくらにするか決めるのが困難。
-   分散が小さいと、パラメタがほとんど変化しないため、効率が悪い。
-   逆に分散が大きいと、とんでもなく的外れなパラメタを提案されやすくなる。
-   その場合のパラメタは確率密度が低くなると予想されるため、採用されにくくなる。

## 2-17.効率の良い乱数生成：HMC法

-   うまい具合にパラメタを変化させるのに、物理の力学のロジックを用いたのが、HMC法。

-   HMC法の説明例え話

    -   谷底に転がるビー玉。
    -   角度のある斜面でビー玉を転がる。
    -   この時ある程度はランダムだが、谷底に近い部分にビー玉が集まりやすくなる。

-   事後分布の確率密度の負の対数をとる。すると、山が谷に変わる。

-   ひっくり返した事後分布から、任意の初期値を選ぶ。この初期値にビー玉を置く。

-   このビー玉をランダムな大きさの力でランダムな方向に弾く。

-   少し時間が経ってからビー玉の位置を調べる。→提案された新しいパラメタ。

-   谷底の方であれば、それが多く発生するということ。

-   事後分布については、確率密度関数がわかっていれば、シミュレーションを実行可能。

-   HMC法は1回の乱数発生にかかる計算コストは高いが、無駄に穴る試行錯誤は少ない。
    そのため、効率よく乱数を生成することが可能。

-   Stanでは、HMC法の1つであるNUTS(No-U-Tern Sampler)を用いている。

## 2-18.用語：MCMC

-   MCMC(Markov Chain Monte Carlo)：マルコフ連鎖モンテカルロ法の略称。
-   マルコフ連鎖：1時点先の値が現在の時点の値だけから決定されるプロセス。
-   モンテカルロ法：乱数を使って何らかの計算を行うこと。
-   MCMCは乱数生成法の枠組みの1つ。
-   HMC法はMCMCの一種。
-   MCMCとしては他にもギブスサンプラーなどがあり、JAGSというソフトウェアでは、
    ギブスサンプラーが主に使われている。
