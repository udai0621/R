---
title: "1章　見せかけの回帰とその対策"
author: "Udai Yokoyama"
date: "2023-01-25"
output:
  md_document:
    variant: markdown_github
---
## 1-1.この章で用いるパッケージ

```{r, echo=TRUE, results=`hide`}
library(urca)
library(lmtest)
library(prais)
library(ggplot2)
library(ggfortify)
library(gridExtra)
```

## 1-2.ホワイトノイズへの回帰分析
- 全く関係ないデータ同士を回帰分析したとしても、有意な係数は得られないはず。
- 正規分布に従うホワイトノイズを複数発生させて、回帰分析を実行し、確認してみる。
```{r}
# 1回のシミュレーションにおけるサンプルサイズ
n_sample <- 400

# 乱数の種
set.seed(1)

# シミュレーションデータの作成
y_wn <- rnorm(n = n_sample)
x_wn <- rnorm(n = n_sample)

# モデルの構築
model_ols_whitenoise <- lm(y_wn ~ x_wn)

# 結果の確認
summary(model_ols_whitenoise)
```
- Coefficientsの部分を見ると、有意な回帰係数が得られていないことがわかる。
- また、決定係数や調整済み決定係数を見ても、説明力のないモデルであることがわかる。

## 1-3.単位根のあるデータ同士の回帰分析
- 次に、単位根のあるデータを対象に回帰分析を行う。
- ホワイトノイズを累積和として、ランダムウォーク過程をシミュレート
```{r}
# 乱数の設定
set.seed(1)

# ランダムウォークするデータ
y_randomwalk <- cumsum(rnorm(n = n_sample))
x_randomwalk <- cumsum(rnorm(n = n_sample))

# モデルの構築
model_ols_randomwalk <- lm(y_randomwalk ~ x_randomwalk)

# 結果の確認
summary(model_ols_randomwalk)
```
- 単位根を持ったデータの場合、p値が有意な回帰係数が得られたということを示している。
- 決定係数についても0.4程度となっており、比較的大きな値となっている。
- このように全く関係のないデータ同士でも有意な回帰係数が得られてしまう現象を「見せかけの回帰」と呼ぶ。
- 実際にどのような回帰直線が引かれのかを図示してみる。
```{r}
# ホワイトノイズの場合
## データの整形
df_whitenoise <- data.frame(x_wn = x_wn, y_wn = y_wn)

## ggplot2による図示
p_whitenoise <- ggplot(df_whitenoise, aes(x=x_wn, y=y_wn)) +   # 外枠
  geom_point() +                                               # 散布図の追加
  geom_smooth(method = "lm", colour = 1) +                     # 回帰直線の追加
  ggtitle("White-Noise")

# ランダムウォークの場合
## データの整形
df_randomwalk <- data.frame(x_randomwalk = x_randomwalk, y_randomwalk = y_randomwalk)

## ggplot2による図示
p_randomwalk <- ggplot(df_randomwalk, aes(x=x_randomwalk, y=y_randomwalk)) +   # 外枠
  geom_point() +                                                               # 散布図の追加
  geom_smooth(method = "lm", colour = 1) +                                     # 回帰直線の追加
  ggtitle("Random-Walk")

# 2つのグラフを表示
grid.arrange(p_whitenoise, p_randomwalk, ncol = 2)
```

## 1-4.定常AR過程への回帰分析
- 次は、単位根ではなく、定常AR過程に従うデータで回帰分析してどうなるか
```{r}
# 乱数の設定
set.seed(2)

# 定常AR過程に従うデータ
y_ar <- arima.sim(
  n = n_sample,
  model = list(order = c(1,0,0), ar = c(0.8))
)
x_ar <- arima.sim(
  n = n_sample,
  model = list(order = c(1,0,0), ar = c(0.8))
)

# モデルの構築
model_ols_ar <- lm(y_ar ~ x_ar)

# 結果の表示
summary(model_ols_ar)

```
- p値が$0.05$以下なので、見せかけの回帰

## 1-5.残差の自己相関と見せかけの回帰
- 見せかけの回帰が発生してしまう大きな理由は「残差に自己相関がある」ということ
- 残差に自己相関がある場合、最小二乗推定量における有効性が失われてしまう。
- つまり、推定されたパラメタが「最も分散が小さい推定量である」という保証が得られないということに。
- 残差に対して正の自己相関があった場合、以下の問題が発生する。
  - 係数の分散を過小推定してしまう
  - 決定係数$R^2$が過大となってしまう。
  - 係数の$t$検定が使えなくなる。
- 残差に自己相関があるということは「まだモデルに組み込むことができていない時系列データの構造が残っている」ということ。

## 1-6.Durbin-Watson検定
- 次に残差の自己相関の有無を調べる方法について。
- 1つ手法であり、多く使われる手法として、Durwin-Watson検定(DW検定)がある。
- DW統計量の定義は以下の通り。サンプルサイズは$T$。

$$
DW = \frac{\sum_{t=2}^T(\hat{u}_t - \hat{u}_{t-1})^2}{\sum_{t=1}^T\hat{u}_t^2}
$$
- $\hat{u}_t$は以下の回帰式の残差にあたる。

$$
y_t = \beta_0 + \beta_1x_t + u_t
$$

- 残差の1次の自己相関が0であった場合は、DW統計量はおよそ$2$
- つまり、$2$からどれほど離れているかを確認することで残差の自己相関について検討がつく。
- また、説明変数が複数個($r$個)持つような重回帰分析の場合でも利用可能

$$
y_t = \beta_0 + \sum_{k=1}^r{\beta_k x_{k,t}} + u_t
$$

```{r}
# DW統計量
residuals_ols <- model_ols_randomwalk$residuals
dw <- sum(diff(residuals_ols)^2) / sum((residuals_ols)^2)
dw
```

- residuals_ols：回帰式の残差であり、$\hat{u}_t$を表現してる。
- 結果としてDW統計量が2よりもかなり小さい値となったため、自己相関があるだろうということがわかる。

- 「サンプルサイズ」と「推定されたパラメータ数」が分かれば、棄却点が計算可能。
- そのため、DW統計量を用いて、残差の自己相関の検定を行うことができる。
- この時の帰無仮説は「自己相関が0である」ということ。
- Rでは、lmtestのdwtest関数を用いることで実行可能。
```{r}
# ホワイトノイズ
dwtest(model_ols_whitenoise)

# ランダムウォーク
dwtest(model_ols_randomwalk)

# AR過程
dwtest(model_ols_ar)

```
- ランダムウォーク過程とAR(1)過程については、p値から帰無仮説が棄却されることがわかる。

## 1-7.シミュレーションによる見せかけの回帰
- 見せかけの回帰がどのくらいの頻度で発生するのかをシミュレーションで確認。

- まずは、回帰分析の結果からp値を取得する。
```{r}
summary(model_ols_whitenoise)$coefficients["x_wn", "Pr(>|t|)"]
```

- 推定されたp値等を格納するための変数などを定義し、シミュレーションを実行
```{r}
# シミュレーションの回数
n_sim <- 200

# 1度のシミュレーションにおけるサンプルサイズ
n_sample <- 400

# p値を格納する変数
p_whitenoise <- numeric(n_sim)
p_randomwalk <- numeric(n_sim)

set.seed(1)

for(i in 1:n_sim){
  # 自己相関のないシミュレーションデータ
  y_whitenoise <- rnorm(n = n_sample)
  x_whitenoise <- rnorm(n = n_sample)
  
  # 線形回帰分析の実行
  model_whitenoise <- lm(y_whitenoise ~ x_whitenoise)
  
  # p値を保存
  p_whitenoise[i] <- summary(model_whitenoise)$coefficients["x_whitenoise", "Pr(>|t|)"]
  
  
  # ランダムウォークのシミュレーションデータ
  y_randomwalk <- cumsum(rnorm(n = n_sample))
  x_randomwalk <- cumsum(rnorm(n = n_sample))
  
  # 線形回帰分析の実行
  model_randomwalk <- lm(y_randomwalk ~ x_randomwalk)
  
  # p値を保存
  p_randomwalk[i] <- summary(model_randomwalk)$coefficients["x_randomwalk", "Pr(>|t|)"]
}

# 有意となった割合を算出する
# TRUEだった場合1を吐き出すので、それを利用して、回数を合計し、シミュレーション回数で割る
## ホワイトノイズ
sum(p_whitenoise < 0.05) / n_sim

## ランダムウォーク
sum(p_randomwalk < 0.05) / n_sim
```
- ランダムウォーク系列に対して回帰分析を実行すると非常に高い割合で見せかけの回帰が起こる。

## 1-8.見せかけの回帰を防ぐ方法
- 見せかけの回帰を防ぐ方法として、過去のデータをモデルに組み込み、データの持つ自己相関を表現するモデルを作るというもの。
- 例として、「ARIMAX」「ベクトル自己回帰(VAR)」「状態空間モデル」等。
- 残差の自己相関を明示的にモデルに組み込む回帰モデルとして、一般化最小二乗法(GLS)がある。
- 差分系列を用いることで、見せかけの回帰は防げるものの、「共和分」という問題が発生するらしい。
- 今後は、以下のような流れ。
  1. 「検定：単位根の有無」「有：2へ」「無：一般化最小二乗法」
  2. 「確認：共和分の有無」「有：???」「無：差分系列への回帰分析」
  
## 1-9.単位根検定
```{r}
# ランダムウォークのADF検定
summary(ur.df(y_randomwalk, type = "none"))

summary(ur.df(x_randomwalk, type = "none"))
```
- 共に、棄却域に満たないため、帰無仮説（単位根である）を棄却することができなかった。

```{r}
# 定常AR(1)過程へのADF検定
summary(ur.df(y_ar, type = "none"))

summary(ur.df(x_ar, type = "none"))

```
- こちらの場合は、棄却域を満たしているので、帰無仮説を棄却し、単位根はなしとなる。

## 1-10.一般化最小二乗法：GLS

- 自己相関を持つデータの場合は、OLSではなく、GLS。
- GLSは、残差の自己相関を明示的にモデルに組み込んだ上で、パラメータ推定する。
- ただし、実際の現場において、自己相関が最初からわかっていることはない。
  1. 自己相関に関わるパラメータOLSで推定
  2. 推定したパラメータを使ってデータを変換
  3. そのデータで再度OLS
- OLSを何度も繰り返し、自己相関のあるデータに対してパラメータを推定する手法を実行可能一般化最小二乗法(FGLS)という。
- やっていることは、残差を使って回帰モデルを作成し、そのパラメータを用いて、元のデータを変換するということ。
- この手法をPrais-Winsten法という。

## 1-11.RによるPrais-Winsten法

```{r}
# Step 1
## 定常AR(1)過程に従うデータをOLSでモデル化
model_ols_ar <- lm(y_ar ~ x_ar)

## 残差
residuals_ols_ar <- model_ols_ar$residuals

## 残差に対してOLSをし、残差の自己相関を表すpを推定
model_residuals <- lm(residuals_ols_ar[-1] ~ residuals_ols_ar[-n_sample] - 1)
p <- as.numeric(model_residuals$coefficients)
p
```

```{r}
# Step 2
## 初期時点のデータを変換
y_transform_1 <- sqrt(1 - p^2) * y_ar[1]
x_transform_1 <- sqrt(1 - p^2) * x_ar[1]
psi_transform_1 <- sqrt(1 - p^2)

## 2時点〜399時点までを変換
y_transform_2 <- y_ar[-1] - p * y_ar[-n_sample]
x_transform_2 <- x_ar[-1] - p * x_ar[-n_sample]
psi_transform_2 <- rep(1-p, n_sample-1)

## それぞれを結合
y_transform_all <- c(y_transform_1, y_transform_2)
x_transform_all <- c(x_transform_1, x_transform_2)
psi_transform_all <- c(psi_transform_1, psi_transform_2)
```

```{r}
# OLS
model_gls_hand <- lm(y_transform_all ~ psi_transform_all + x_transform_all - 1)
summary(model_gls_hand)
```
- 結果として、p値が0.7378ということで、有意な回帰係数は得られないという結果に。
- つまり、見せかけの回帰を回避できたということ。

## 1-12.パッケージを使ったGLS

- praisパッケージのprais.winsten関数を使用。（data.frame型のみ受付）

```{r}
# 型変換
d <- data.frame(
  y_ar = y_ar,
  x_ar = x_ar
)
#class(y_ar)

# Prais-Winsten
model_gls_PW <- prais_winsten(y_ar ~ x_ar, data = d,index = 1:nrow(d), max_iter = 1)
model_gls_PW
```
- Iterationsを増やすことで、繰り返し残差の計算〜変換を行うことができる。

## 1-13.差分系列への回帰分析

- 単位根があるデータへの回帰分析->差分系列を回帰分析👌

```{r}
model_lm_diff <- lm(diff(y_randomwalk) ~ diff(x_randomwalk))
summary(model_lm_diff)
```

## 1-14.共和分

- 単位根を持つデータ同士で回帰分析すると見せかけの回帰になることが多い
- 例外として、共和分を持っているとならない。
- 共和分：データ $y_t$ と $x_t$ がそれぞれ単位根を持っているが、$y_t$ と $x_t$の線型結合では単位根を持たなくなる関係
- 共和分関係を持つデータの特徴をシミュレーション。

```{r}
set.seed(10)

# データセット作成
randomwalk <- cumsum(rnorm(n = n_sample))
x_cointegration <- 0.6 * randomwalk + rnorm(n = n_sample)
y_cointegration <- 0.4 * randomwalk + rnorm(n = n_sample)

# ADF検定で単位根を持つことの確認
summary(ur.df(y_cointegration, type = "none"))
summary(ur.df(x_cointegration, type = "none"))
```

- 線形結合したら、ホワイトノイズとなってしまうことを図示して確認

```{r}
# データを1つのdata.frameにまとめる
df <- data.frame(
  y_cointegration = y_cointegration,
  x_cointegration = x_cointegration,
  z = x_cointegration - (0.6/0.4)*y_cointegration  # 線形結合
)

# ts型に変換
ts_df <- ts(df)

# 図示
autoplot(ts_df, facets = T)  # 複数の時系列に分けたグラフを描く

```

## 1-15.共和分検定

- Engle-Grangerの手法で検定してみる。
- この手法は２変数での共和分関係を調べることにしか使えない。
- 手順としては下記の通り。
  1. 単位根を持つデータに対して、OLS
  2. 残差を計算
  3. 残差に対して単位根検定->単位根がなくなれば、共和分関係である。
- 手順3の検定に関しては、残差に対しての検定になるので、ADF検定、KPSS検定は使用不可
- Phillips-Ouliaris検定(PO検定)を用いる。帰無仮説は「共和分関係がない」こと。

```{r}
# データの整形
data_matrix <- matrix(nrow = n_sample, ncol = 2)
data_matrix[,1] <- y_cointegration
data_matrix[,2] <- x_cointegration

# 共和分検定
summary(ca.po(data_matrix, demean = "none"))  # 定数項もトレンドもないことを過程してモデル化している。
```

```{r}
# 共和分のあるデータに、差分とってから回帰
y_cointegration_diff <- diff(y_cointegration)
x_cointegration_diff <- diff(x_cointegration)

model_lm_diff_cointegration <- lm(y_cointegration_diff ~ x_cointegration_diff)
summary(model_lm_diff_cointegration)
```
- 上記のように共和分関係にあるデータに対して、差分系列への回帰分析をすると、本来の関係が見えなくなる。
- このために、差分を取ることには注意が必要になってくる。